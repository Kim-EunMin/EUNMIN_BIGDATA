result <- myfunc(5,8)
result
myfunc <- function(x,y){
val.sum <- x+y
val.mul <- x*y
return (list(sum=val.sum,mul=val.mul))
}
result <- myfunc(5,8)
s <- result$sum
s <- result$sum;s
result
s <- result$sum
s <- result$sum;s
m <- result$mul
m <- result$mul;m
cat('5+8=',s,'\n')
cat('5*8=',m,'\n')
myfunc <- function(x,y){
val.sum <- x+y
val.mul <- x*y
return (list(sum=val.sum,mul=val.mul))
}
result <- myfunc(5,8)
s <- result$sum
m <- result$mul
cat('5+8=',s,'\n')
cat('5*8=',m,'\n')
myfunc <- function(x,y){
val.sum <- x+y
val.mul <- x*y
}
return (list(sum=val.sum,mul=val.mul))
#Matrix 생성
z <- matrix(1:20,nrow=4)    #R에서는 디폴트로 열 먼저 채운다(열 우선 방식)
z
z <- matrix(1:20,ncol=4)
z
z <- matrix(1:20,nrow=4,ncol=5)
z
z <- matrix(1:20,nrow=4,ncol=5,byrow=T)       #행 우선
z
x <- 1:4
x
y <- 5:8
y
z <- matrix(1:20,nrow=4,ncol=5)
z
m1 <- cbind(x,y)
m1
m2 <- rbind(x,y)
m2
m3 <- rbind(m2,x)
m3
m4 <- cbind(z,x)
z
m4
z
#Matrix 에서 cell의 값 추출
z[2,3]            #2행3열 (값 하나)
z[1,4]
z[2,]             #열은 생략, 행 전체 의미한다
z[,4]             #4열 전체
z[2,1:3]
z
z[1,c(1,2,4)]
z[1:2,]
z[,c(1,4)]
#Matrix에서 행/열 에 이름 지정
score <- matrix(c(90,85,69,78,
85,96,49,95,
90,80,70,70),
nrow=4,ncol=3)
score
rownames(score) <- c("Hong","Kim","Lee","Yoo")
score
colnames(score) <- c("English","Math","Science")
score
score["Hong","Math"]
score["Kim",c("Math","Science")]
score["Lee",]
score[,"English"]
class(score[,"English"])
rownames (score)
colnames(score)
colnames(score)[2]
,
#Data Frame 생성
city <- c("Seoul","Tokyo","Washington")
,
#Data Frame 생성
city <- c("Seoul","Tokyo","Washington")
rank <- c(1,3,2)
city.info <- data.frame(city,rank)
city.info                               #dataframe 은 변수이름이 명확하게 나옴
str(city.info)                               #dataframe 은 변수이름이 명확하게 나옴
,
#Data Frame 생성
name <- c("Hong","Kim","Lee")
age <- c(22,20,25)
gender=factor(c("M","F","M"))
blood.type=factor(c("A","O","B"))
person.info <- data.frame(name,age,gender,blood.type)
person.info
,
#Data Frame 생성
person2.info <- data.frame(name=c("Hong","Kim","Lee"),
age=c(22,20,25),
gender=factor(c("M","F","M")),
blood.type=factor(c("A","O","B")))
person2.info
,
#Data Frame 생성
city.info[1,1]
,
#Data Frame 생성
city.info
city.info[1,1]
,
#Data Frame 생성
class(city.info[1,1])
city.info[1,1]
city.info[1,]
city.info
city.info[1,1]
city.info[1,]
city.info[,1]
city.info[city.info$city,]    #여기서는 오류다
city.info[,"rank"]
#Data Frame 생성
person.info
person.info$name
person.info[person.info$name=="Hong",]
person.info[person.info$name=="Hong",c("name","age")]
data()             #R에서 기본적으로 제공하는 dataset
iris
iris[,c(1:2)]
iris[,c(1,3,5)]
iris[,c("Sepal.Length","Species")]
iris[1:5,]
iris[1:5,c(1,3)]
#Matrix 와 Data Frame 에서 사용하는 함수
dim(person.info)              #(데이터 분석에 많이 쓰임) 관측치,변수 갯수
nrow(person.info)
nrow( m3 )
m3
ncol(person.info)
head(iris)                    #앞부분 일부
tail(iris)                    #뒷부분 일부
str(iris)                     #(데이터 분석에 중요하다)정보제공 (dataframe 형태이다. 150개 관측치, 5개변수다, $뒤가 변수내용이다, datatype 이 나오는데, 몇몇 변수는 자동으로 factor 가 된게 보인다)
str(city.info)
str(person.info)
iris[,5]
unique(iris[,5])              #중복된 데이터가 많을때 종류만 나열해라
table(iris[,"Species"])       #(데이터 분석에 많이 쓴다) factor 타입을 count 해준다.
table(person.info[,"blood.type"])
table(person.info[,"gender"])
person.info
table(person.info[,"blood.type"])
table(person.info[,"gender"])
colSums(iris[,-5])            #각 열의 합계(5열은 제외해라)
colSums(iris[,-5])            #각 열의 합계(5열은 제외해라)
#Matrix/Data Frame 사용 함수
#행별/열별 합계와 평균 계산
head(iris)
apply(iris[,1:4],2,sum)       #apply함수는 인수3개 (대상,숫자가1이면 행방향 2이면 열방향,하려는 동작)
colMeans(iris[,-5])           #각 열의 평균(각 변수의 평균)
apply(iris[,1:4],2,mean)      #2니까 각 변수의 평균 즉 세로의 평균 구해라
876.5/150
colMeans(iris[,-5])           #각 열의 평균(각 변수의 평균)
apply(iris[,1:4],2,mean)      #2니까 각 변수의 평균 즉 세로의 평균 구해라
rowSums(iris[,-5])            #각 행의 합계 (그래서 150개 벡터가 나옴)
head(iris)
5.1+3.5+1.4+0.2
rowSums(iris[,-5])            #각 행의 합계 (그래서 150개 벡터가 나옴)
rowSums(iris[,-5])            #각 행의 합계 (그래서 150개 벡터가 나옴)
rowSums(iris[,-5])            #각 행의 합계 (그래서 150개 벡터가 나옴)
apply(iris[,-5],1,sum)
#각 행의 합계 (그래서 150개 벡터가 나옴)
apply(iris[,-5],1,sum)
rowMeans(iris[,-5])
#
#4일차
#2019-11-29
10.2/5
#
#4일차
#2019-11-29
10.2/4
rowMeans(iris[,-5])
apply(iris[,-5],1,mean)
apply(iris[,-5],2,median)     #apply 가 더 많이 쓰인다.
#행/열 방향 전환
z <- matrix(1:20,nrow=4,ncol=5);
z
t(z)
iris
head(iris)
#조건에 맞는 행과 열의 값 추출(Data Frame만 가능)
IR.1 <- subset(iris,Species=="setosa")
IR.1
IR.2 <- subset(iris,Sepal.Length>5.0 &Sepal.Width >4.0)
IR.2
IR.2[,c(2,4)]
IR.1 <- subset(iris,Species=="setosa")
IR.1
#Matrix/Data Frame 산술연산
a <- matrix(1:20,4,5);a
b <- matrix(21:40,4,5);b
2*a
b-5
2*a+3*b
b/a
a*b
class(iris)
str(iris)
class(state.x77)  ; str(state.x77)
class(state.x77)
str(state.x77)
is.matrix(iris)
is.data.frame(iris)
is.matrix(state.x77)
is.data.frame(state.x77)
st <- data.frame(state.x77)
str(st)
head(st)
class(st)
iris.m <- as.matrix(iris[,1:4])
head(iris.m)
class(iris.m)
dim(st)    #관측치 50, 변수 8개
iris.m
st
str(iris.m)
head(st)
Population
head(st)
Population
attach(st)  #attach 를 하면  변수명 직접적으로 쓸 수 있다. (열하나가 벡터인데 attach 를 써서 그걸 이름만 불러도 불러오는게 가능)
Population
st
Population
Population
detach(st)  #detach 를 하면 이제 안됨
Population
air <- read.csv("airquality.csv",header=T)     #header 첫줄을 head로 인식하냐마냐(데이터부터 나오면 F로 해야함)
class(air)
dim(air)
str(air)      #int 도 숫자로 생각하기 (그러나 오류날수도 있으니 as.number 로 바꿔주기)
head(air)
tail(air)       #요거 5개는 파일을 읽어올때 꼭 해주자
name <- "hong"
str_replace(name,"h","")
name
library(stringi)
str_replace(name,"h","")
library(stringr)
name <- "hong"
str_replace(name,"h","")
name
money <- str(money,",","")
money
#
#4일차
#2019-11-29
money <- "1,123"
money <- str_replace(money,",","")
money
name <- c("Hong","Kim","Lee")
age <- c(22,20,25)
gender=factor(c("M","F","M"))
blood.type=factor(c("A","O","B"))
person.info <- data.frame(name,age,gender,blood.type)
person.info
setwd("D:/WorkR")
write.csv(person.info,"person_info.csv",row.names=F)
write.csv(person.info,"persondd_info.csv",row.names=F)
Sys.setenv ( JAVA_HOME = 'C:/Program Files/Java/jre1.8.0_231') #java 실행환경 위치를 지정해준다. jre 위치 지정(슬래시로 바꾼다)
library(wordcloud)
library(wordcloud2)
library(KoNLP)            #checking user defined dictionary! 라는 설명이 뜬다. KoNLP 에는 사전이 몇개가 있는데, 사전에 따라 저장된 단어수가 다르다. 사용할 때 사전 설정하는게 있다. 후에 진행
library(RColorBrewer)
library(dplyr)            #위에 4개는 워드클라우드에 필요한 패키지/ 아래 2개는 시각화에 쓰는 패키지
library(ggplot2)
library(wordcloud)
library(wordcloud2)
library(KoNLP)            #checking user defined dictionary! 라는 설명이 뜬다. KoNLP 에는 사전이 몇개가 있는데, 사전에 따라 저장된 단어수가 다르다. 사용할 때 사전 설정하는게 있다. 후에 진행
library(RColorBrewer)
setwd("D:/EUNMIN_BIGDATA")
text <- readLines("mis_document.txt",encoding="UTF-8")
setwd("D:/EUNMIN_BIGDATA")
text <- readLines("mis_document.txt",encoding="UTF-8")
text
#자료 수집 했으니, 명사 뽑아 오자.
#(문장이니까 분석이 안되니까 분석할 대상, 즉 명사를 뽑아오자.)
buildDictionary(ext_dic = "woorimalsam" )  #"우리말씀" 한글사전
buildDictionary(ext_dic = "woorimalsam" )  #"우리말씀" 한글사전
pal2 <- brewer.pal( 8, "Dark2" )           #색상 팔레트 생성             #8번 다크계열의 색상을 쓸거다.
noun <- sapply(text,extractNoun, USE.NAMES = F )  #명사 추출           #이게 실제 명사 추출하는 것이다. (옵션해석하면 : 명사추출해라, UseNAMES=f 는 행이름은 안쓰겠다는것)
noun     # 사전에 있는 명사들만 뽑아낸다. 실제로는 원본 파일과 비교해서 빠진 단어가 있나 확인해봐야한다. (이게 텍스트 마이닝의 자료 처리 과정 중 하나 이다)
noun2 <- unlist( noun ) #list <- vector 로 변환
noun2
wordcount <- table(noun2) #빈도체크
wordcount
sort.noun <- sort(wordcount,decreasing=T)[1:10]  #빈도가 높은것에서 낮은 순으로 정렬
sort.noun
sort.noun <- sort.noun[-1]  #공백이여서 이건 의미없으니까  제거해준것이다.
sort.noun
sort.noun
barplot(sort.noun, names.arg = names(sort.noun),
col="steelblue", main="빈도수 높은 단어",
ylab="단어빈도수")
sort.noun
df <- as.data.frame(sort.noun)
df
ggplot(df,aes(x=df$noun2,y=df$Freq)) +
geom_bar(stat="identity",
width=0.7,
fill="steelblue") +
ggtitle("빈도수 높은 단어") +
theme(plot.title=element_text(size=25,
face="bold",
colour="steelblue",
hjust=0,
vjust=1)) +
labs(x="명사",y="단어빈도수")
df <- as.data.frame(sort.noun)
df
ggplot(df,aes(x=df$noun2,y=df$Freq)) +
geom_bar(stat="identity",
width=0.7,
fill="steelblue") +
ggtitle("빈도수 높은 단어") +
theme(plot.title=element_text(size=25,
face="bold",
colour="steelblue",
hjust=0,
vjust=1)) +
labs(x="명사",y="단어빈도수") +
geom_text(aes(label=df$Freq),hjust=-0.3) + #빈도표시
coord_flip()
wordcount
talle(noun2)
word2
table(noun2)
wordcount <- table(noun2)
wordcount
noun2
wordcount <- table(noun2)
wordcount
sort.noun <- sort(wordcount,decreasing=T)[1:10]
sort.noun
wordcount
names(wordcount)
wordcloud ( names(wordcount),    #단어           (출력할 단어가 오는 것)
freq=wordcount,        #단어 빈도        (빈도에 대한 정보를 넣는다)
scale=c(6,0.7),        #단어 폰트 크기(최대,최소)
min.freq=3,            #단어최소빈도         #빈도수 최소 이정도 이상만 나타내라 ( 빈도가 3이상인것만 cloud 에 표현해라)
random.order=F,        #단어출력위치           #출력위치가 F 이면 빈도가 높은게 가운데로 몰린다.
rot.per=.1,            #90도 회전단어비율            #회전된 단어들의 비율 (10% 만 회전시켜라)
colors=pal2)           #단어 색
wordcloud ( names(wordcount),    #단어           (출력할 단어가 오는 것)
freq=wordcount,        #단어 빈도        (빈도에 대한 정보를 넣는다)
scale=c(6,0.7),        #단어 폰트 크기(최대,최소)
min.freq=3,            #단어최소빈도         #빈도수 최소 이정도 이상만 나타내라 ( 빈도가 3이상인것만 cloud 에 표현해라)
random.order=T,        #단어출력위치           #출력위치가 F 이면 빈도가 높은게 가운데로 몰린다.
rot.per=.1,            #90도 회전단어비율            #회전된 단어들의 비율 (10% 만 회전시켜라)
colors=pal2)           #단어 색
wordcloud ( names(wordcount),    #단어           (출력할 단어가 오는 것)
freq=wordcount,        #단어 빈도        (빈도에 대한 정보를 넣는다)
scale=c(6,0.7),        #단어 폰트 크기(최대,최소)
min.freq=3,            #단어최소빈도         #빈도수 최소 이정도 이상만 나타내라 ( 빈도가 3이상인것만 cloud 에 표현해라)
random.order=F,        #단어출력위치           #출력위치가 F 이면 빈도가 높은게 가운데로 몰린다.
rot.per=.1,            #90도 회전단어비율            #회전된 단어들의 비율 (10% 만 회전시켜라)
colors=pal2)           #단어 색
wordcloud ( names(wordcount),    #단어           (출력할 단어가 오는 것)
freq=wordcount,        #단어 빈도        (빈도에 대한 정보를 넣는다)
scale=c(6,0.7),        #단어 폰트 크기(최대,최소)
min.freq=3,            #단어최소빈도         #빈도수 최소 이정도 이상만 나타내라 ( 빈도가 3이상인것만 cloud 에 표현해라)
random.order=F,        #단어출력위치           #출력위치가 F 이면 빈도가 높은게 가운데로 몰린다.
rot.per=.8,            #90도 회전단어비율            #회전된 단어들의 비율 (10% 만 회전시켜라)
colors=pal2)           #단어 색
pal3 <- brewer.pal(9,"Blues")[5:9]
wordcloud ( names(wordcount),      # 단어          (출력할 단어가 오는 것)
freq=wordcount,        # 단어 빈도      (빈도에 대한 정보를 넣는다)
scale=c(6,0.7),        # 단어 폰트 크기(최대,최소)
min.freq=3,            # 단어최소빈도    => 빈도수 최소 이정도 이상만 나타내라 ( 빈도가 3이상인것만 cloud 에 표현해라)
random.order=F,        # 단어출력위치    => 출력위치가 F 이면 빈도가 높은게 가운데로 몰린다.
rot.per=.1,            # 90도 회전단어비율   => 회전된 단어들의 비율 (10% 만 회전시켜라)
colors=pal3)
noun <- sapply(text,extractNoun,USE.NAMES = F)          #단어 추가해서 사전이 바뀌었으니까, 다시 단어추출을 한다.
noun2 <- unlist(noun)
noun <- sapply(text,extractNoun,USE.NAMES = F)          #단어 추가해서 사전이 바뀌었으니까, 다시 단어추출을 한다.
noun
noun2 <- unlist(noun)
noun2
noun2
table(wordcount)
library(KoNLP)
useSystemDic()            #사전이다.28만단어 가지고 있는 사전
useSejongDic()            #사전임.
useNIADic()               #사전임.
#2. 텍스트 데이터 가져오기
word_data <-readLines("애국가(가사).txt")
word_data
#2. 텍스트 데이터 가져오기
word_data <-readLines("애국가(가사).txt")
word_data
word_data
# 사전-> 명사추출-> 벡터화 -> 워드클라우드 -> 전처리(추가, 삭제)
# readline, buildDictionary ,sapply
#unlist, wordcloud, user_dic, gsub
#3. 명사추출
word_data2 <- sapply(word_data,extractNoun,USE.NAMES=F)
word_data2
add_words <- c("백두산","남산","철갑","가을","하늘","달")
word_data2 <- sapply(word_data, extractNoun, USE.NAMES = F)
word_data2
#4. 행렬을 벡터로 변환
undata <- unlist( word_data2 )
undata
#5. 사용빈도확인
word_table <- table(undata)
word_table
undata2 <- undata[nchar(undata)>=2]
undata2 <- undata[nchar(undata)>=2]
undata2
word_table2 <- table(undata2)
word_table2
#7. 데이터 정렬
sort(word_table2,decreasing=T)
library(wordcloud2)
wordcloud2(word_table2)
#8.1 배경 및 색상 변경
wordcloud2(word_table2,
color='random-light',
backgroundColor="black")
wordcloud2(word_table2, fontFamily="맑은고딕",size=1.2,color="random-light", #color 는 글자색상,  size 는 글자 크기
,
shape="star")
wordcloud2(word_table2, fontFamily="맑은고딕",size=1.2,color="random-light", #color 는 글자색상,  size 는 글자 크기
backgroundColor="black",
shape="star")
wordcloud2(word_table2, fontFamily="맑은고딕",size=1.2, #color 는 글자색상,  size 는 글자 크기
backgroundColor="black",
shape="star")
#8.3 선택 색상 반복
wordcloud2(word_table2, size=1.6, color= rep_len(c("red","blue"),
nrow(word_table2))) #2가지 색상으로만 표현
word_table2
wordcloud2(demoFreq, size=1.6,color=rep_len(c("red","blue"),
nrow(word_table2)))
#8.4 일정 방향 정렬
wordcloud2(word_table2, minRotation=-pi/6,
maxRotation=-pi/6,
rotateRatio=1)
wordcloud2(demoFreq,minRotation=-0.5,
maxRotation=0.52,rotateRatio=1.3)
library(wordcloud)
library(wordcloud2)
library(KoNLP)
library(RColorBrewer)
set("D:/EUNMIN_BIGDATA")
setwd("D:/EUNMIN_BIGDATA")
library(KoNLP)
text <- readLines("ex_10-4.txt",encoding="UTF-8")
text
buildDictionar(ext_dic="wooimalsam")
buildDictionary(ext_dic="wooimalsam")
noun <- sapply(text,extractNoun,USE.NAMES=F)
noun
noun2 <- unlist(noun)
noun2
wordcount <- table(noun2)
sort.noun <- sort(wordcount,decreasing=T)[1:10]
sort.noun
pal2 <- brewer.pal(8,"dark2")
pal2 <- brewer.pal(8,"Dark2")
wordcount
wordclout(names(wordcount),freq=wordcount,
scale=c(6,0.7),min.freq=3,
random.order=F,
rot.per=.1,colors=pal2)
wordcloud(names(wordcount),freq=wordcount,
scale=c(6,0.7),min.freq=3,
random.order=F,
rot.per=.1,colors=pal2)
useNIADic()
text <- readLines( "ex_10-4.txt", encoding = "UTF-8" )
text
noun <- sapply( text, extractNoun, USE.NAMES = F )
noun
noun2 <- unlist(noun)
noun2 <- noun2[ nchar(noun2) > 1 ]
wordcount <- table( noun2 )
wordcloud2( wordcount,
color = rep_len( c( 'red', 'blue'),
nrow( wordcount ) ),
minRotation = -pi / 6,
maxRotation = -pi / 6,
rotateRatio = 1 )
wordcloud(names(wordcount),freq=wordcount,
scale=c(6,0.7),min.freq=3,
random.order=F,
rot.per=.1,colors=pal2)
wordcloud(names(wordcount),freq=wordcount,
scale=c(6,0.7),min.freq=1,
random.order=F,
rot.per=.1,colors=pal2)
wordcloud(names(wordcount),freq=wordcount,
scale=c(6,0.7),min.freq=1,
random.order=F,
rot.per=.1,colors=pal2)
